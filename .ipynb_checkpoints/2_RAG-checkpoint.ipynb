{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "961e70ee-3588-43d2-a818-aaa5a34396d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T13:37:44.296014Z",
     "iopub.status.busy": "2025-07-19T13:37:44.295730Z",
     "iopub.status.idle": "2025-07-19T13:38:56.168069Z",
     "shell.execute_reply": "2025-07-19T13:38:56.167624Z",
     "shell.execute_reply.started": "2025-07-19T13:37:44.295997Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/lonhai/LangChain_Deploy/my_langChain_venv/my_venv_first/lib/python3.11/site-packages/_distutils_hack/__init__.py:53: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'我是AI助手，我能够帮助你回答各种问题，无论是语言相关的问题还是其他类型的查询。如果你有任何问题，欢迎随时告诉我！'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######  1. 模型准备 #######\n",
    "# LLMs模型加载\n",
    "from qwen2_llm import Qwen\n",
    "llm = Qwen()\n",
    "llm.invoke('你是谁')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0db347a7-3a21-43ed-bd55-bf4df239c0fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T13:40:30.205778Z",
     "iopub.status.busy": "2025-07-19T13:40:30.205404Z",
     "iopub.status.idle": "2025-07-19T13:42:22.066707Z",
     "shell.execute_reply": "2025-07-19T13:42:22.066045Z",
     "shell.execute_reply.started": "2025-07-19T13:40:30.205761Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, maia, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m encode_kwargs = {\u001b[33m'\u001b[39m\u001b[33mnormalize_embeddings\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 加载词嵌入模型\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m hf = \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 模型名称\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 模型参数\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 模型转向量的参数\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m hf.embed_query(\u001b[33m'\u001b[39m\u001b[33m你是\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/workspace/lonhai/LangChain_Deploy/my_langChain_venv/my_venv_first/lib/python3.11/site-packages/langchain_huggingface/embeddings/huggingface.py:94\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     92\u001b[39m     model_cls = sentence_transformers.SentenceTransformer\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28mself\u001b[39m._client = \u001b[43mmodel_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/workspace/lonhai/LangChain_Deploy/my_langChain_venv/my_venv_first/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:367\u001b[39m, in \u001b[36mSentenceTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[38;5;28mself\u001b[39m.is_hpu_graph_enabled = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.default_prompt_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.default_prompt_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.prompts:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/workspace/lonhai/LangChain_Deploy/my_langChain_venv/my_venv_first/lib/python3.11/site-packages/torch/nn/modules/module.py:1299\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1213\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m   1214\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Move and/or cast the parameters and buffers.\u001b[39;00m\n\u001b[32m   1215\u001b[39m \n\u001b[32m   1216\u001b[39m \u001b[33;03m    This can be called as\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1297\u001b[39m \n\u001b[32m   1298\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1299\u001b[39m     device, dtype, non_blocking, convert_to_format = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_parse_to\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1301\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1303\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1304\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (dtype.is_floating_point \u001b[38;5;129;01mor\u001b[39;00m dtype.is_complex):\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, maia, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu"
     ]
    }
   ],
   "source": [
    "## embedding模型加载\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"Qwen/Qwen3-Embedding-0.6B\"\n",
    "model_kwargs = {'device': 'gpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "# 加载词嵌入模型\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name, # 模型名称\n",
    "    model_kwargs=model_kwargs, # 模型参数\n",
    "    encode_kwargs=encode_kwargs # 模型转向量的参数\n",
    ")\n",
    "hf.embed_query('你是')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a4cf4-2d87-4aab-9557-e6273c5ca23c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My_LangChain_Env",
   "language": "python",
   "name": "my_venv_first"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
